# ğŸ§  LLMâ€‘AssistantÂ StarterÂ Kit

A handsâ€‘on project for **learning** how to structure, prompt, extend and fineâ€‘tune LLMâ€‘powered applications. What began as a oneâ€‘file chatbot has grown into a modular playground for **prompt engineering**, **memory handling**, **summarisation** and (soon) RAG & fineâ€‘tuning.

---

## Key Objectives

* **Learn by doing** â€“ prompts, context windows, safety & memory techniques.
* **Repeatable workflows** â€“ versioned releases, tests, GitHubÂ Projects.
* **Modular code** â€“ swap in new backâ€‘ends (Redis memory, vectorÂ DB, containers).

---

## ProjectÂ Status

| Track             | Version      | Notes                                           |
| ----------------- | ------------ | ----------------------------------------------- |
| **LatestÂ stable** | **`v0.4.2`** | Contextâ€‘window trimming, crossâ€‘platform hygiene |
| **InÂ progress**   | **`v0.4.3`** | ğŸ—„ï¸Â Memory interface & summarisation scaffold   |
| **PlannedÂ next**  | **`v0.4.4`** | ğŸ”§Â Automated tests & CI                         |

*Full changelog*: **[ReleaseÂ Notes](./docs/release_notes.md)**

---

## DirectoryÂ Map

```text
.
â”œâ”€â”€ main.py                 # Gradio chat loop & prompt pipeline
â”œâ”€â”€ utils/
â”‚Â Â  â”œâ”€â”€ memory.py           # Inâ€‘memory backend facade (v0.4.3)
â”‚Â Â  â”œâ”€â”€ aliases.py          # Alias â†’ concept mappings
â”‚Â Â  â”œâ”€â”€ prompt_utils.py     # Inâ€‘order token alias match helper
â”‚Â Â  â””â”€â”€ safety_filters.py   # Profanity & safety checks
â”œâ”€â”€ config/
â”‚Â Â  â”œâ”€â”€ settings.json       # Runtime config (safety, memory, logging â€¦)
â”‚Â Â  â”œâ”€â”€ prompt_template.txt # Base system prompt
â”‚Â Â  â””â”€â”€ specialized_prompts.json
â”œâ”€â”€ experiments/            # Exploratory notebooks & scripts
â”œâ”€â”€ tests/                  # (Planned) pytest suites
â””â”€â”€ docs/                   # Roadmap Â· Scope Â· Dev checklist Â· â€¦
```

---

## WorkflowÂ & Planning

Work is managed in **GitHubÂ Projects** â†’ [ProjectÂ Board](https://github.com/users/Deim0s13/projects/4/views/1).

```
Initiative â†’ Epic â†’ Milestone (version) â†’ Issue (task)
```

* Every change begins as an **Issue** linked to its Epic/Milestone.
* PRs flow **feature â†’ dev â†’ main** and include `fixesÂ #id`.

See full guidelines in **[`CONTRIBUTING.md`](./docs/CONTRIBUTING.md)**.

### Visual overview

```mermaid
graph TD
  A[Initiative ğŸ§­] --> B[Epic ğŸ“‚ PromptÂ &Â Safety]
  A                --> C[Epic ğŸ“‚ MemoryÂ &Â Summary]
  B --> D[Milestone v0.4.0]
  B --> E[Milestone v0.4.1]
  C --> F[Milestone v0.4.2]
  C --> G[Milestone v0.4.3]
  D --> H[Issue âœ… AliasÂ logic]
  E --> I[Issue âœ… SafetyÂ filters]
  F --> J[Issue âœ… ContextÂ trimming]
  G --> K[Issue ğŸ›  MemoryÂ interface]
  G --> L[Issue ğŸ›  SummariseÂ scaffold]
```

---

## Quickâ€‘startÂ ğŸƒâ€â™‚ï¸

```bash
git clone https://github.com/<you>/llm-assistant.git
cd llm-assistant

python -m venv venv   # optional but recommended
source venv/bin/activate  # Windows: venv\Scripts\activate

pip install -r requirements.txt
python main.py
```

---

### EnvironmentÂ Overrides (`.env`)

Create a `.env` in project root to tweak config **without** editing `settings.json`.

```env
DEBUG_MODE=true
LOG_TO_FILE=true
MAX_HISTORY_TURNS=6
MODEL_DEVICE=cpu   # cpu|cuda|mps
```

Supported keys & examples â†’ **docs/dev\_checklist.md**

---

### PlatformÂ Setup ğŸ’»

| OS                   | Key steps                                                                                                               |
| -------------------- | ----------------------------------------------------------------------------------------------------------------------- |
| **macOSÂ (Mâ€‘series)** | PythonÂ 3.10+, `pip install torch torchvision torchaudio` (MPS wheels)                                                   |
| **WindowsÂ +Â CUDA**   | Install CUDAÂ Toolkit then `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121` |

More detail & troubleshooting â†’ **Crossâ€‘Platform Dev Checklist**.

---

## LearningÂ Roadmap

1. **PhaseÂ 1** â€“ Prompt engineering & baseline chatbot.
2. **PhaseÂ 2** â€“ Fineâ€‘tuning (LoRAÂ /Â QLoRA) with tracking.
3. **PhaseÂ 3** â€“ Packaging & scaling (containers, RAG, agents).

See **[`ROADMAP.md`](./docs/roadmap.md)** for specifics.

---

## Useful Links

* ğŸ—‚Â Board â€“ [https://github.com/users/Deim0s13/projects/4/views/1](https://github.com/users/Deim0s13/projects/4/views/1)
* ğŸ“Â [Scope](./docs/scope.md)
* ğŸªµÂ [ReleaseÂ Notes](./docs/release_notes.md)
* ğŸ”¬Â [ExperimentsÂ Tracker](./docs/experiments_tracker.md)

---

## FutureÂ Vision âœ¨

* Persistent memory backâ€‘ends (Redis / vectorÂ DB)
* Automated regression tests & CI
* RAG pipelines for knowledgeâ€‘base answers
* Containerised deployment on OpenShift
* Devâ€‘agent capabilities & selfâ€‘evaluation loops

> **Stay curious. Iterate often. Share learnings.**
