# ğŸ§  LLMâ€‘AssistantÂ StarterÂ Kit

A handsâ€‘on project for **learning** how to structure, prompt, extend, *and eventually fineâ€‘tune* LLMâ€‘powered applications. What began as a singleâ€‘file chatbot has grown into a modular playground for **prompt engineering**, **memory handling**, **summarisation**, and (next) **RAG** & **fineâ€‘tuning**.

---

## Key Objectives

* **Learn by doing** â€“ iterate on prompts, context windows, safety & memory techniques.
* **Repeatable workflows** â€“ versioned releases, Pytest + Ruff checks, GitHub Projects for kanâ€‘ban.
* **Modular code** â€“ swap backâ€‘ends (Redis memory, vectorâ€¯DB, containers) with minimal friction.

---

## ProjectÂ Status

| Track             | Version      | Notes                                                                                           |
| ----------------- | ------------ | ----------------------------------------------------------------------------------------------- |
| **LatestÂ stable** | **`v0.4.3`** | Inâ€‘memory backend, summarise scaffold, first wave of unitâ€‘tests                                 |
| **InÂ progress**   | **`v0.4.4`** | ğŸ”§ **RedisMemoryBackend** (persistent memory), ğŸ“ Summarise MVP, ğŸ¤– CI pipeline (pytest + Ruff) |
| **PlannedÂ next**  | **`v0.4.5`** | ğŸ§© Vectorâ€‘DB memory, ğŸª„ RAG prototype, Docker/Podman containers                                 |

*See the full history â†’ **[Releaseâ€¯Notes](./docs/release_notes.md)**.*

---

## DirectoryÂ Map <small>(key paths only)</small>

```text
.
â”œâ”€â”€ main.py                         # Gradio chat loop & prompt pipeline
â”œâ”€â”€ memory/                         # Unified faÃ§ade + concrete backâ€‘ends
â”‚   â”œâ”€â”€ __init__.py                 # Memory.create(<backend>) factory
â”‚   â”œâ”€â”€ backends/
â”‚   â”‚   â”œâ”€â”€ in_memory_backend.py    # default volatile store
â”‚   â”‚   â””â”€â”€ redis_memory_backend.py # v0.4.4 persistent store
â”‚   â””â”€â”€ summariser.py               # summarise_context() scaffold
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ aliases.py                  # Keyword â†’ concept mappings
â”‚   â”œâ”€â”€ prompt_utils.py             # Orderâ€‘preserving alias helper
â”‚   â””â”€â”€ safety_filters.py           # Profanity & safety checks
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.json               # Runtime config (memory, model, logging â€¦)
â”‚   â”œâ”€â”€ prompt_template.txt         # Base system prompt
â”‚   â””â”€â”€ specialised_prompts.json
â”œâ”€â”€ tests/                          # PyTest suites (memory, summariser â€¦)
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ activate_tests.sh           # helper â†’ sets PYTHONPATH + runs smoke tests
â””â”€â”€ docs/                           # Roadmap Â· Scope Â· Dev checklist Â· â€¦
```

---

## WorkflowÂ & Planning

Work is managed in **GitHubÂ Projects** â†’ â–¶ [LLM Project Board](https://github.com/users/Deim0s13/projects/4/views/1)

```
Initiative â†’ Epic â†’ Milestone (version) â†’ Issue (task)
```

* Every change starts as an **Issue** linked to its Epic & Milestone.
* PR flow: **feature â†’ dev â†’ main** with `FixesÂ #<id>` semantics.

See full contributor guidelines in **[`CONTRIBUTING.md`](./docs/CONTRIBUTING.md)**.

---

## Quickâ€‘start ğŸƒâ€â™‚ï¸

```bash
git clone https://github.com/<you>/llm-assistant.git
cd llm-assistant

python -m venv venv          # optional but recommended
source venv/bin/activate     # Windows: venv\Scripts\activate

pip install -r requirements.txt
python main.py
```

### Run with Redis (optional)

```bash
# Local Redis via Docker
podman run --name redis -p 6379:6379 -d docker.io/redis:7-alpine

export REDIS_URL="redis://localhost:6379/0"
python main.py --memory redis       # or edit config/settings.json
```

If Redis is unavailable the app automatically falls back to volatile memory.

---

### EnvironmentÂ Overrides (`.env`)

Drop a `.env` in the project root to override `settings.json` without touching tracked config:

```env
DEBUG_MODE=true
MAX_HISTORY_TURNS=6
MODEL_DEVICE=mps      # cpu | cuda | mps
```

Supported keys & examples â†’ **docs/dev\_checklist.md**

---

### PlatformÂ Setup ğŸ’»

| OS                   | Key steps                                                                                                               |
| -------------------- | ----------------------------------------------------------------------------------------------------------------------- |
| **macOSÂ (Mâ€‘series)** | Install PythonÂ 3.10+, then `pip install torch torchvision torchaudio` (MPS wheels)                                      |
| **WindowsÂ +Â CUDA**   | Install CUDAÂ Toolkit then `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121` |

More detail & troubleshooting â†’ **Crossâ€‘Platform Dev Checklist**.

---

## Unitâ€‘tests ğŸ§ª

Run smoke tests & memoryâ€‘toggle checks:

```bash
source scripts/activate_tests.sh       # sets PYTHONPATH + runs tests
# or
pytest -q                              # full suite
```

CI (GitHubÂ Actions) kicks off in **v0.4.4** (Ruff + PyTest on every PR).

---

## LearningÂ Roadmap

1. **PhaseÂ 1** â€“ Prompt engineering & baseline chatbot *(v0.1 â†’ v0.4.x)*
2. **PhaseÂ 2** â€“ Fineâ€‘tuning playground *(v0.5 â†’ v0.7)*
3. **PhaseÂ 3** â€“ Packaging, scaling & RAG *(v0.8 â†’ v1.0)*

See **[`ROADMAP.md`](./docs/roadmap.md)** for milestoneâ€‘level detail.

---

## Useful Links

* ğŸ—‚ Board â€“ [https://github.com/users/Deim0s13/projects/4/views/1](https://github.com/users/Deim0s13/projects/4/views/1)
* ğŸ“‘ [Scope](./docs/scope.md)
* ğŸªµ [ReleaseÂ Notes](./docs/release_notes.md)
* ğŸ”¬ [ExperimentsÂ Tracker](./docs/experiments_tracker.md)
* ğŸ“ [SummarisationÂ Planning](./docs/summarisation_planning.md)
* ğŸ—„ï¸ [Memory Flow](./docs/memory_flow.md)

---

## FutureÂ Vision âœ¨

* Vectorâ€‘DB (FAISS / Milvus) for semantic memory
* Automated regression tests & CI matrix
* RAG pipelines for knowledgeâ€‘base answers
* Containerised deployment (Podman / OpenShift)
* Devâ€‘agent capabilities & selfâ€‘evaluation loops

> **Stay curious. Iterate often. Share your learnings.**
